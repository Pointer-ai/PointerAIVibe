// AI Assistant æœåŠ¡å±‚

import { getAPIConfig } from '../../modules/profileSettings/service'
import { AssistantConfig, ChatSession, LearningProgress, ChatMessage } from './types'
import { log, error } from '../../utils/logger'
import { getProfileData, setProfileData } from '../../utils/profile'
import { addActivityRecord } from '../../modules/profileSettings/service'

/**
 * è·å–ç”¨æˆ·å®Œæ•´çš„å­¦ä¹ ä¸Šä¸‹æ–‡
 */
const getUserCompleteContext = async (): Promise<string> => {
  try {
    // è·å–æ ¸å¿ƒæ•°æ®æ¨¡å—
    const { getLearningGoals, getLearningPaths, getCourseUnits, getAbilityProfile } = await import('../../modules/coreData')
    const { getCurrentProfile } = await import('../../utils/profile')
    const { getCurrentAssessment } = await import('../../modules/abilityAssess/service')
    
    // è·å–å„ç§æ•°æ®
    const goals = getLearningGoals()
    const paths = getLearningPaths()
    const courseUnits = getCourseUnits()
    const abilityProfile = getAbilityProfile()
    const currentProfile = getCurrentProfile()
    const currentAssessment = getCurrentAssessment() // è·å–è¯¦ç»†è¯„ä¼°æ•°æ®
    
    // ä»è¯„ä¼°æ•°æ®ä¸­æå–ä¼˜åŠ¿å’Œå¼±åŠ¿
    let strengthsInfo = 'æœªåˆ†æ'
    let weaknessesInfo = 'æœªåˆ†æ'
    
    if (currentAssessment?.report) {
      strengthsInfo = currentAssessment.report.strengths?.join(', ') || 'æœªåˆ†æ'
      weaknessesInfo = currentAssessment.report.improvements?.join(', ') || 'æœªåˆ†æ'
    }
    
    // ç»„è£…ä¸Šä¸‹æ–‡ä¿¡æ¯
    const context = `
ğŸ§‘â€ğŸ’¼ ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯:
- æ¡£æ¡ˆåç§°: ${currentProfile?.name || 'æœªè®¾ç½®'}
- æ˜¯å¦å®Œæˆèƒ½åŠ›è¯„ä¼°: ${abilityProfile ? 'æ˜¯' : 'å¦'}
${abilityProfile ? `- æ€»ä½“èƒ½åŠ›è¯„åˆ†: ${abilityProfile.overallScore}/100
- ä¼˜åŠ¿é¢†åŸŸ: ${strengthsInfo}
- å¾…æ”¹è¿›é¢†åŸŸ: ${weaknessesInfo}` : ''}

ğŸ“‹ å­¦ä¹ ç›®æ ‡ç°çŠ¶:
- æ€»ç›®æ ‡æ•°: ${goals.length}ä¸ª
- æ¿€æ´»ç›®æ ‡: ${goals.filter(g => g.status === 'active').length}ä¸ª
- è¿›è¡Œä¸­ç›®æ ‡: ${goals.filter(g => g.status === 'active').map(g => `"${g.title}" (${g.category}, ${g.targetLevel})`).join(', ') || 'æ— '}
- æš‚åœç›®æ ‡: ${goals.filter(g => g.status === 'paused').length}ä¸ª
- å·²å®Œæˆç›®æ ‡: ${goals.filter(g => g.status === 'completed').length}ä¸ª

ğŸ›¤ï¸ å­¦ä¹ è·¯å¾„ç°çŠ¶:
- æ€»è·¯å¾„æ•°: ${paths.length}ä¸ª  
- æ¿€æ´»è·¯å¾„: ${paths.filter(p => p.status === 'active').length}ä¸ª
- å½“å‰å­¦ä¹ è·¯å¾„: ${paths.filter(p => p.status === 'active').map(p => `"${p.title}" (${p.nodes?.length || 0}ä¸ªèŠ‚ç‚¹)`).join(', ') || 'æ— '}

ğŸ“š è¯¾ç¨‹å†…å®¹ç°çŠ¶:
- æ€»è¯¾ç¨‹å•å…ƒ: ${courseUnits.length}ä¸ª
- è¯¾ç¨‹ç±»å‹åˆ†å¸ƒ: ${getContentTypeDistribution(courseUnits)}
- æœ€è¿‘åˆ›å»º: ${courseUnits.length > 0 ? courseUnits[courseUnits.length - 1].title : 'æ— '}

ğŸ’¡ å­¦ä¹ å»ºè®®:
${generateContextualSuggestions(goals, paths, courseUnits, abilityProfile)}
`.trim()
    
    return context
  } catch (error) {
    log('[Context] Failed to get user context:', error)
    return 'âš ï¸ æ— æ³•è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡æ•°æ®'
  }
}

/**
 * è·å–è¯¾ç¨‹å†…å®¹ç±»å‹åˆ†å¸ƒ
 */
const getContentTypeDistribution = (courseUnits: any[]): string => {
  if (courseUnits.length === 0) return 'æ— '
  
  const distribution: Record<string, number> = {}
  courseUnits.forEach(unit => {
    const type = unit.type || 'æœªåˆ†ç±»'
    distribution[type] = (distribution[type] || 0) + 1
  })
  
  return Object.entries(distribution)
    .map(([type, count]) => `${type}(${count})`)
    .join(', ')
}

/**
 * ç”ŸæˆåŸºäºå½“å‰çŠ¶æ€çš„å»ºè®®
 */
const generateContextualSuggestions = (goals: any[], paths: any[], courseUnits: any[], abilityProfile: any): string => {
  const suggestions: string[] = []
  
  // åŸºäºç›®æ ‡çŠ¶æ€çš„å»ºè®®
  if (goals.length === 0) {
    suggestions.push('å»ºè®®å…ˆåˆ›å»ºå­¦ä¹ ç›®æ ‡')
  } else if (goals.filter(g => g.status === 'active').length === 0) {
    suggestions.push('å»ºè®®æ¿€æ´»ä¸€äº›å­¦ä¹ ç›®æ ‡')
  } else if (goals.filter(g => g.status === 'active').length > 3) {
    suggestions.push('å»ºè®®æ§åˆ¶æ¿€æ´»ç›®æ ‡æ•°é‡åœ¨3ä¸ªä»¥å†…')
  }
  
  // åŸºäºè·¯å¾„çŠ¶æ€çš„å»ºè®®
  if (paths.length === 0 && goals.length > 0) {
    suggestions.push('å»ºè®®ä¸ºç›®æ ‡ç”Ÿæˆå­¦ä¹ è·¯å¾„')
  }
  
  // åŸºäºèƒ½åŠ›è¯„ä¼°çš„å»ºè®®
  if (!abilityProfile) {
    suggestions.push('å»ºè®®å®Œæˆèƒ½åŠ›è¯„ä¼°ä»¥è·å¾—ä¸ªæ€§åŒ–æŒ‡å¯¼')
  }
  
  // åŸºäºè¯¾ç¨‹å†…å®¹çš„å»ºè®®
  if (courseUnits.length === 0 && paths.length > 0) {
    suggestions.push('å»ºè®®ä¸ºå­¦ä¹ è·¯å¾„åˆ›å»ºå…·ä½“çš„è¯¾ç¨‹å†…å®¹')
  }
  
  return suggestions.length > 0 ? suggestions.join('ï¼›') : 'å­¦ä¹ çŠ¶æ€è‰¯å¥½ï¼Œç»§ç»­ä¿æŒ'
}

/**
 * è·å–å­¦ä¹ è¿›åº¦æ•°æ®
 */
export const getLearningProgress = (): LearningProgress => {
  const progress = getProfileData('aiAssistantProgress') as LearningProgress
  return progress || {
    keywordQueries: {},
    chatSessions: [],
    totalInteractions: 0,
    lastActivity: new Date()
  }
}

/**
 * ä¿å­˜å­¦ä¹ è¿›åº¦æ•°æ®
 */
export const saveLearningProgress = (progress: LearningProgress): void => {
  setProfileData('aiAssistantProgress', progress)
  log('[AIAssistant] Learning progress saved')
}

/**
 * åˆ›å»ºæ–°çš„èŠå¤©ä¼šè¯
 */
export const createChatSession = (trigger: 'manual' | 'keyword' = 'manual', keyword?: string): ChatSession => {
  const now = new Date()
  const timeString = now.toLocaleTimeString('zh-CN', { hour: '2-digit', minute: '2-digit' })
  
  const session: ChatSession = {
    id: Date.now().toString() + Math.random().toString(36).substr(2, 9),
    title: keyword ? `${keyword}` : `å¯¹è¯ ${timeString}`,
    messages: [],
    createdAt: now,
    lastActivity: now,
    trigger,
    keyword,
    isActive: true
  }
  
  log('[AIAssistant] New chat session created:', session.id, trigger, keyword)
  return session
}

/**
 * æ›´æ–°ä¼šè¯æ ‡é¢˜ï¼ˆåŸºäºç¬¬ä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
 */
export const updateSessionTitle = (session: ChatSession, firstMessage: string): ChatSession => {
  if (session.messages.length > 0) return session // å·²æœ‰æ¶ˆæ¯ï¼Œä¸æ›´æ–°æ ‡é¢˜
  
  // æå–ç¬¬ä¸€å¥è¯ä½œä¸ºæ ‡é¢˜ï¼ˆæœ€å¤š20ä¸ªå­—ç¬¦ï¼‰
  const firstSentence = firstMessage.split(/[ã€‚ï¼ï¼Ÿ\.\!\?]/)[0].trim()
  const title = firstSentence.length > 20 
    ? firstSentence.substring(0, 17) + '...' 
    : firstSentence || session.title
  
  return {
    ...session,
    title: title
  }
}

/**
 * è·å–æ‰€æœ‰èŠå¤©ä¼šè¯
 */
export const getChatSessions = (): ChatSession[] => {
  const progress = getLearningProgress()
  return progress.chatSessions.sort((a, b) => new Date(b.lastActivity).getTime() - new Date(a.lastActivity).getTime())
}

/**
 * ä¿å­˜èŠå¤©ä¼šè¯
 */
export const saveChatSession = (session: ChatSession): void => {
  const progress = getLearningProgress()
  
  // æ›´æ–°æˆ–æ·»åŠ ä¼šè¯
  const sessionIndex = progress.chatSessions.findIndex(s => s.id === session.id)
  if (sessionIndex >= 0) {
    progress.chatSessions[sessionIndex] = session
  } else {
    progress.chatSessions.unshift(session)
  }
  
  // ä¿æŒæœ€å¤š10ä¸ªä¼šè¯
  progress.chatSessions = progress.chatSessions.slice(0, 10)
  
  // æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
  progress.lastActivity = new Date()
  progress.totalInteractions++
  
  saveLearningProgress(progress)
}

/**
 * åˆ é™¤èŠå¤©ä¼šè¯
 */
export const deleteChatSession = (sessionId: string): void => {
  const progress = getLearningProgress()
  progress.chatSessions = progress.chatSessions.filter(s => s.id !== sessionId)
  saveLearningProgress(progress)
  log('[AIAssistant] Chat session deleted:', sessionId)
}

/**
 * è·å–å­¦ä¹ ç»Ÿè®¡
 */
export const getLearningStats = () => {
  const progress = getLearningProgress()
  
  const totalKeywords = Object.keys(progress.keywordQueries).length
  const totalQueries = Object.values(progress.keywordQueries).reduce((sum, q) => sum + q.count, 0)
  const mostQueriedKeywords = Object.entries(progress.keywordQueries)
    .sort(([,a], [,b]) => b.count - a.count)
    .slice(0, 5)
    .map(([keyword, data]) => ({ keyword, count: data.count }))
  
  return {
    totalKeywords,
    totalQueries,
    totalSessions: progress.chatSessions.length,
    totalInteractions: progress.totalInteractions,
    mostQueriedKeywords,
    lastActivity: progress.lastActivity
  }
}

/**
 * è·å–AIåŠ©æ‰‹é…ç½®
 */
export const getAssistantConfig = (): AssistantConfig | null => {
  try {
    const apiConfig = getAPIConfig()
    
    if (!apiConfig.key) {
      return null
    }
    
    return {
      apiKey: apiConfig.key,
      model: apiConfig.model,
      specificModel: apiConfig.specificModel,
      params: apiConfig.params
    }
  } catch (err) {
    error('[AIAssistant] Failed to get config:', err)
    return null
  }
}

/**
 * æ£€æŸ¥AIåŠ©æ‰‹æ˜¯å¦å¯ç”¨
 */
export const isAssistantAvailable = (): boolean => {
  const config = getAssistantConfig()
  return config !== null
}

/**
 * è°ƒç”¨AI APIè·å–å›å¤
 */
export const getAIResponse = async (message: string, context?: string): Promise<string> => {
  const config = getAssistantConfig()
  if (!config) {
    throw new Error('AIåŠ©æ‰‹é…ç½®ä¸å¯ç”¨')
  }
  
  log('[AIAssistant] Starting API call with config:', {
    model: config.model,
    specificModel: config.specificModel,
    hasApiKey: !!config.apiKey,
    apiKeyPrefix: config.apiKey?.substring(0, 10) + '...',
    params: config.params
  })
  
  try {
    let apiUrl = ''
    let headers: Record<string, string> = {
      'Content-Type': 'application/json'
    }
    let body: any = {}
    
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå­¦ä¹ åŠ©æ‰‹ - Agent æ¨¡å¼ (Previewç‰ˆæœ¬)

ğŸŒŸ PREVIEWç‰ˆæœ¬è¯´æ˜ï¼š
â€¢ è¿™æ˜¯AI Agentæ¨¡å¼çš„é¢„è§ˆç‰ˆæœ¬ï¼ŒåŠŸèƒ½æŒç»­ä¼˜åŒ–ä¸­
â€¢ ç”¨æˆ·çš„å®Œæ•´å­¦ä¹ æ•°æ®å·²ç»ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ï¼Œæ— éœ€ä½¿ç”¨å·¥å…·è·å–æ•°æ®
â€¢ ä¸“æ³¨äºåŸºäºç°æœ‰æ•°æ®æä¾›æ™ºèƒ½åˆ†æå’Œå»ºè®®

ä½ çš„æ ¸å¿ƒèŒè´£ï¼š
â€¢ ğŸ§  åŸºäºç”¨æˆ·ä¸Šä¸‹æ–‡æä¾›æ™ºèƒ½å­¦ä¹ å»ºè®®
â€¢ ğŸ¯ åˆ†æç”¨æˆ·å½“å‰å­¦ä¹ çŠ¶æ€å¹¶ç»™å‡ºä¸ªæ€§åŒ–æŒ‡å¯¼
â€¢ ğŸ“ˆ æ ¹æ®èƒ½åŠ›è¯„ä¼°å’Œå­¦ä¹ è¿›åº¦æä¾›ä¼˜åŒ–å»ºè®®
â€¢ ğŸ’¡ å›ç­”å­¦ä¹ ç›¸å…³é—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
â€¢ ğŸš€ å¸®åŠ©ç”¨æˆ·åˆ¶å®šå­¦ä¹ è®¡åˆ’å’Œè°ƒæ•´å­¦ä¹ ç­–ç•¥

âš ï¸ PREVIEWç‰ˆæœ¬é™åˆ¶ï¼š
â€¢ æš‚ä¸æ”¯æŒæ•°æ®ä¿®æ”¹æ“ä½œï¼ˆåˆ›å»ºã€æ›´æ–°ã€åˆ é™¤ï¼‰
â€¢ ä¸“æ³¨äºåˆ†æã€å»ºè®®å’ŒæŒ‡å¯¼åŠŸèƒ½
â€¢ æ‰€æœ‰æ•°æ®æŸ¥è¯¢å·²é€šè¿‡ä¸Šä¸‹æ–‡æä¾›ï¼Œæ— éœ€é¢å¤–è·å–

ğŸ’¬ äº¤äº’åŸåˆ™ï¼š
1. ç›´æ¥åŸºäºæä¾›çš„ç”¨æˆ·ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜
2. æä¾›å…·ä½“ã€å¯è¡Œçš„å­¦ä¹ å»ºè®®
3. åˆ†æç”¨æˆ·çš„ä¼˜åŠ¿å’Œæ”¹è¿›ç©ºé—´
4. ç»™å‡ºä¸ªæ€§åŒ–çš„å­¦ä¹ è·¯å¾„å»ºè®®
5. åœ¨é€‚å½“æ—¶å€™æé†’è¿™æ˜¯Previewç‰ˆæœ¬

ğŸ“Š å½“å‰ç”¨æˆ·å®Œæ•´ä¸Šä¸‹æ–‡ï¼š
${context ? context : 'æ— '}`
    
    switch (config.model) {
      case 'openai':
        apiUrl = 'https://api.openai.com/v1/chat/completions'
        headers['Authorization'] = `Bearer ${config.apiKey}`
        body = {
          model: config.specificModel || 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: message }
          ],
          temperature: config.params?.temperature || 0.7,
          max_tokens: config.params?.maxTokens || 1000
        }
        
        // æ·»åŠ å…¶ä»–å‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ä¸”æœ‰æ•ˆï¼‰
        if (config.params?.topP !== undefined && config.params.topP > 0) {
          body.top_p = config.params.topP
        }
        if (config.params?.presencePenalty !== undefined) {
          body.presence_penalty = config.params.presencePenalty
        }
        if (config.params?.frequencyPenalty !== undefined) {
          body.frequency_penalty = config.params.frequencyPenalty
        }
        if (config.params?.stopSequences && config.params.stopSequences.length > 0) {
          body.stop = config.params.stopSequences
        }
        break
        
      case 'claude':
        apiUrl = 'https://api.anthropic.com/v1/messages'
        headers['x-api-key'] = config.apiKey
        headers['anthropic-version'] = '2023-06-01'
        body = {
          model: config.specificModel || 'claude-3-5-sonnet-20241022',
          system: systemPrompt,
          messages: [{ role: 'user', content: message }],
          max_tokens: config.params?.maxTokens || 2000,
          temperature: config.params?.temperature || 0.3
        }
        
        // ä¸å†æ·»åŠ å·¥å…·å®šä¹‰ï¼Œæ”¹ä¸ºçº¯æ–‡æœ¬å¯¹è¯æ¨¡å¼ (Previewç‰ˆæœ¬)
        break
        
      case 'qwen':
        apiUrl = 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation'
        headers['Authorization'] = `Bearer ${config.apiKey}`
        headers['X-DashScope-SSE'] = 'disable'
        body = {
          model: config.specificModel || 'qwen-turbo',
          input: {
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: message }
            ]
          },
          parameters: {
            temperature: config.params?.temperature || 0.3,
            max_tokens: config.params?.maxTokens || 2000,
            result_format: 'message'
          }
        }
        
        // ä¸å†æ·»åŠ å·¥å…·å®šä¹‰ï¼Œæ”¹ä¸ºçº¯æ–‡æœ¬å¯¹è¯æ¨¡å¼ (Previewç‰ˆæœ¬)
        break
        
      default:
        throw new Error(`ä¸æ”¯æŒçš„AIæ¨¡å‹: ${config.model}`)
    }
    
    log('[AIAssistant] API Request details:', { 
      url: apiUrl,
      headers: { ...headers, Authorization: headers.Authorization?.substring(0, 20) + '...' },
      bodyKeys: Object.keys(body),
      messageLength: message.length
    })
    
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers,
      body: JSON.stringify(body)
    })
    
    log('[AIAssistant] Response status:', response.status, response.statusText)
    
    if (!response.ok) {
      let errorMessage = `APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`
      try {
        const errorData = await response.json()
        error('[AIAssistant] API Error Details:', errorData)
        if (errorData.error) {
          if (typeof errorData.error === 'string') {
            errorMessage += `\né”™è¯¯ä¿¡æ¯: ${errorData.error}`
          } else if (errorData.error.message) {
            errorMessage += `\né”™è¯¯ä¿¡æ¯: ${errorData.error.message}`
          } else {
            errorMessage += `\né”™è¯¯è¯¦æƒ…: ${JSON.stringify(errorData.error)}`
          }
        }
      } catch (parseError) {
        error('[AIAssistant] Failed to parse error response:', parseError)
        errorMessage += '\næ— æ³•è§£æé”™è¯¯å“åº”'
      }
      throw new Error(errorMessage)
    }
    
    const data = await response.json()
    log('[AIAssistant] API Response keys:', Object.keys(data))
    
    // è§£æä¸åŒAIæœåŠ¡çš„å“åº”æ ¼å¼
    let aiResponse = ''
    switch (config.model) {
      case 'openai':
        aiResponse = data.choices?.[0]?.message?.content || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚'
        break
      case 'claude':
        aiResponse = data.content?.[0]?.text || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚'
        break
      case 'qwen':
        aiResponse = data.output?.text || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚'
        break
    }
    
    log('[AIAssistant] AI response processed successfully, length:', aiResponse.length)
    return aiResponse
    
  } catch (err) {
    error('[AIAssistant] API call failed:', err)
    if (err instanceof Error) {
      throw new Error(`AIåŠ©æ‰‹è°ƒç”¨å¤±è´¥: ${err.message}`)
    } else {
      throw new Error('AIåŠ©æ‰‹æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚')
    }
  }
}

/**
 * æµå¼è°ƒç”¨AI APIè·å–å›å¤
 */
export const getAIResponseStream = async (
  message: string, 
  context?: string,
  onChunk?: (chunk: string) => void
): Promise<string> => {
  const config = getAssistantConfig()
  if (!config) {
    throw new Error('AIåŠ©æ‰‹é…ç½®ä¸å¯ç”¨')
  }
  
  try {
    let apiUrl = ''
    let headers: Record<string, string> = {
      'Content-Type': 'application/json'
    }
    let body: any = {}
    
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå­¦ä¹ åŠ©æ‰‹ - Agent æ¨¡å¼ (Previewç‰ˆæœ¬)

ğŸŒŸ PREVIEWç‰ˆæœ¬è¯´æ˜ï¼š
â€¢ è¿™æ˜¯AI Agentæ¨¡å¼çš„é¢„è§ˆç‰ˆæœ¬ï¼ŒåŠŸèƒ½æŒç»­ä¼˜åŒ–ä¸­
â€¢ ç”¨æˆ·çš„å®Œæ•´å­¦ä¹ æ•°æ®å·²ç»ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ï¼Œæ— éœ€ä½¿ç”¨å·¥å…·è·å–æ•°æ®
â€¢ ä¸“æ³¨äºåŸºäºç°æœ‰æ•°æ®æä¾›æ™ºèƒ½åˆ†æå’Œå»ºè®®

ä½ çš„æ ¸å¿ƒèŒè´£ï¼š
â€¢ ğŸ§  åŸºäºç”¨æˆ·ä¸Šä¸‹æ–‡æä¾›æ™ºèƒ½å­¦ä¹ å»ºè®®
â€¢ ğŸ¯ åˆ†æç”¨æˆ·å½“å‰å­¦ä¹ çŠ¶æ€å¹¶ç»™å‡ºä¸ªæ€§åŒ–æŒ‡å¯¼
â€¢ ğŸ“ˆ æ ¹æ®èƒ½åŠ›è¯„ä¼°å’Œå­¦ä¹ è¿›åº¦æä¾›ä¼˜åŒ–å»ºè®®
â€¢ ğŸ’¡ å›ç­”å­¦ä¹ ç›¸å…³é—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
â€¢ ğŸš€ å¸®åŠ©ç”¨æˆ·åˆ¶å®šå­¦ä¹ è®¡åˆ’å’Œè°ƒæ•´å­¦ä¹ ç­–ç•¥

âš ï¸ PREVIEWç‰ˆæœ¬é™åˆ¶ï¼š
â€¢ æš‚ä¸æ”¯æŒæ•°æ®ä¿®æ”¹æ“ä½œï¼ˆåˆ›å»ºã€æ›´æ–°ã€åˆ é™¤ï¼‰
â€¢ ä¸“æ³¨äºåˆ†æã€å»ºè®®å’ŒæŒ‡å¯¼åŠŸèƒ½
â€¢ æ‰€æœ‰æ•°æ®æŸ¥è¯¢å·²é€šè¿‡ä¸Šä¸‹æ–‡æä¾›ï¼Œæ— éœ€é¢å¤–è·å–

ğŸ’¬ äº¤äº’åŸåˆ™ï¼š
1. ç›´æ¥åŸºäºæä¾›çš„ç”¨æˆ·ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜
2. æä¾›å…·ä½“ã€å¯è¡Œçš„å­¦ä¹ å»ºè®®
3. åˆ†æç”¨æˆ·çš„ä¼˜åŠ¿å’Œæ”¹è¿›ç©ºé—´
4. ç»™å‡ºä¸ªæ€§åŒ–çš„å­¦ä¹ è·¯å¾„å»ºè®®
5. åœ¨é€‚å½“æ—¶å€™æé†’è¿™æ˜¯Previewç‰ˆæœ¬

ğŸ“Š å½“å‰ç”¨æˆ·å®Œæ•´ä¸Šä¸‹æ–‡ï¼š
${context ? context : 'æ— '}`
    
    switch (config.model) {
      case 'openai':
        apiUrl = 'https://api.openai.com/v1/chat/completions'
        headers['Authorization'] = `Bearer ${config.apiKey}`
        body = {
          model: config.specificModel || 'gpt-3.5-turbo',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: message }
          ],
          temperature: config.params?.temperature || 0.7,
          max_tokens: config.params?.maxTokens || 1000,
          stream: true // å¯ç”¨æµå¼è¾“å‡º
        }
        
        // æ·»åŠ å…¶ä»–å‚æ•°ï¼ˆå¦‚æœå­˜åœ¨ä¸”æœ‰æ•ˆï¼‰
        if (config.params?.topP !== undefined && config.params.topP > 0) {
          body.top_p = config.params.topP
        }
        if (config.params?.presencePenalty !== undefined) {
          body.presence_penalty = config.params.presencePenalty
        }
        if (config.params?.frequencyPenalty !== undefined) {
          body.frequency_penalty = config.params.frequencyPenalty
        }
        if (config.params?.stopSequences && config.params.stopSequences.length > 0) {
          body.stop = config.params.stopSequences
        }
        break
        
      case 'claude':
        apiUrl = 'https://api.anthropic.com/v1/messages'
        headers['x-api-key'] = config.apiKey
        headers['anthropic-version'] = '2023-06-01'
        body = {
          model: config.specificModel || 'claude-3-5-sonnet-20241022',
          system: systemPrompt,
          messages: [{ role: 'user', content: message }],
          max_tokens: config.params?.maxTokens || 2000,
          temperature: config.params?.temperature || 0.3
        }
        
        // ä¸å†æ·»åŠ å·¥å…·å®šä¹‰ï¼Œæ”¹ä¸ºçº¯æ–‡æœ¬å¯¹è¯æ¨¡å¼ (Previewç‰ˆæœ¬)
        break
        
      case 'qwen':
        apiUrl = 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation'
        headers['Authorization'] = `Bearer ${config.apiKey}`
        body = {
          model: config.specificModel || 'qwen-turbo',
          input: {
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: message }
            ]
          },
          parameters: {
            temperature: config.params?.temperature || 0.3,
            max_tokens: config.params?.maxTokens || 2000,
            result_format: 'message'
          }
        }
        
        // ä¸å†æ·»åŠ å·¥å…·å®šä¹‰ï¼Œæ”¹ä¸ºçº¯æ–‡æœ¬å¯¹è¯æ¨¡å¼ (Previewç‰ˆæœ¬)
        break
        
      default:
        throw new Error(`ä¸æ”¯æŒçš„AIæ¨¡å‹: ${config.model}`)
    }
    
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers,
      body: JSON.stringify(body)
    })
    
    if (!response.ok) {
      let errorMessage = `APIè¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`
      try {
        const errorData = await response.json()
        if (errorData.error) {
          if (typeof errorData.error === 'string') {
            errorMessage += `\né”™è¯¯ä¿¡æ¯: ${errorData.error}`
          } else if (errorData.error.message) {
            errorMessage += `\né”™è¯¯ä¿¡æ¯: ${errorData.error.message}`
          }
        }
      } catch (parseError) {
        errorMessage += '\næ— æ³•è§£æé”™è¯¯å“åº”'
      }
      throw new Error(errorMessage)
    }
    
    // å¤„ç†æµå¼å“åº”
    const reader = response.body?.getReader()
    if (!reader) {
      throw new Error('æ— æ³•è·å–å“åº”æµ')
    }
    
    const decoder = new TextDecoder()
    let fullResponse = ''
    let chunkBuffer = '' // ç¼“å†²åŒºç”¨äºç´¯ç§¯å°çš„chunk
    
    // é˜²æŠ–å‡½æ•°ï¼Œé¿å…è¿‡äºé¢‘ç¹çš„æ›´æ–°
    let updateTimer: NodeJS.Timeout | null = null
    const flushBuffer = () => {
      if (chunkBuffer && onChunk) {
        onChunk(chunkBuffer)
        chunkBuffer = ''
      }
    }
    
    try {
      while (true) {
        const { done, value } = await reader.read()
        if (done) break
        
        const chunk = decoder.decode(value)
        const lines = chunk.split('\n')
        
        for (const line of lines) {
          if (line.trim() === '') continue
          
          try {
            let content = ''
            
            if (config.model === 'openai') {
              // OpenAI æµå¼æ ¼å¼: data: {"choices":[{"delta":{"content":"..."}}]}
              if (line.startsWith('data: ')) {
                const jsonStr = line.slice(6)
                if (jsonStr === '[DONE]') continue
                
                const data = JSON.parse(jsonStr)
                content = data.choices?.[0]?.delta?.content || ''
              }
            } else if (config.model === 'claude') {
              // Claude æµå¼æ ¼å¼: event: content_block_delta\ndata: {"delta":{"text":"..."}}
              if (line.startsWith('data: ')) {
                const data = JSON.parse(line.slice(6))
                content = data.delta?.text || ''
              }
            } else if (config.model === 'qwen') {
              // é€šä¹‰åƒé—®æµå¼æ ¼å¼: data:{"output":{"text":"..."}}
              if (line.startsWith('data:')) {
                const data = JSON.parse(line.slice(5))
                content = data.output?.text || ''
                // é€šä¹‰åƒé—®æ˜¯å¢é‡å¼çš„ï¼Œéœ€è¦è®¡ç®—å·®å€¼
                if (content.startsWith(fullResponse)) {
                  content = content.slice(fullResponse.length)
                }
              }
            }
            
            if (content) {
              fullResponse += content
              chunkBuffer += content
              
              // ä½¿ç”¨é˜²æŠ–æœºåˆ¶ï¼Œæ¯50msæœ€å¤šæ›´æ–°ä¸€æ¬¡
              if (updateTimer) {
                clearTimeout(updateTimer)
              }
              updateTimer = setTimeout(flushBuffer, 50)
            }
          } catch (parseError) {
            // å¿½ç•¥è§£æé”™è¯¯ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€è¡Œ
            continue
          }
        }
      }
      
      // ç¡®ä¿æœ€åçš„å†…å®¹è¢«å‘é€
      if (updateTimer) {
        clearTimeout(updateTimer)
      }
      flushBuffer()
      
    } finally {
      reader.releaseLock()
    }
    
    if (!fullResponse) {
      fullResponse = 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚'
    }
    
    return fullResponse
    
  } catch (err) {
    error('[AIAssistant] Stream API call failed:', err)
    if (err instanceof Error) {
      throw new Error(`AIåŠ©æ‰‹è°ƒç”¨å¤±è´¥: ${err.message}`)
    } else {
      throw new Error('AIåŠ©æ‰‹æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚')
    }
  }
}

/**
 * AIèŠå¤©æœåŠ¡ç±» - æä¾›åº•å±‚èŠå¤©åŠŸèƒ½
 */
export class AIChatService {
  private messages: ChatMessage[] = []
  private isLoading = false
  private streamingMessageId: string | null = null
  private streamingContent = ''
  
  // äº‹ä»¶å›è°ƒ
  private onMessagesUpdate?: (messages: ChatMessage[]) => void
  private onLoadingStateChange?: (isLoading: boolean) => void
  private onStreamingUpdate?: (messageId: string, content: string) => void
  private onStreamingComplete?: (messageId: string, finalContent: string) => void

  constructor(
    callbacks?: {
      onMessagesUpdate?: (messages: ChatMessage[]) => void
      onLoadingStateChange?: (isLoading: boolean) => void
      onStreamingUpdate?: (messageId: string, content: string) => void
      onStreamingComplete?: (messageId: string, finalContent: string) => void
    }
  ) {
    if (callbacks) {
      this.onMessagesUpdate = callbacks.onMessagesUpdate
      this.onLoadingStateChange = callbacks.onLoadingStateChange
      this.onStreamingUpdate = callbacks.onStreamingUpdate
      this.onStreamingComplete = callbacks.onStreamingComplete
    }
  }

  /**
   * è·å–å½“å‰æ¶ˆæ¯åˆ—è¡¨
   */
  getMessages(): ChatMessage[] {
    return [...this.messages]
  }

  /**
   * è·å–åŠ è½½çŠ¶æ€
   */
  getLoadingState(): boolean {
    return this.isLoading
  }

  /**
   * è·å–æµå¼å†…å®¹
   */
  getStreamingContent(): { messageId: string | null; content: string } {
    return {
      messageId: this.streamingMessageId,
      content: this.streamingContent
    }
  }

  /**
   * æ¸…ç©ºèŠå¤©è®°å½•
   */
  clearMessages(): void {
    this.messages = []
    this.onMessagesUpdate?.(this.messages)
    log('[AIChatService] Messages cleared')
  }

  /**
   * æ·»åŠ æ¶ˆæ¯
   */
  addMessage(message: ChatMessage): void {
    this.messages.push(message)
    this.onMessagesUpdate?.(this.messages)
  }

  /**
   * æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯
   */
  updateLastMessage(updatedMessage: ChatMessage): void {
    if (this.messages.length > 0) {
      this.messages[this.messages.length - 1] = updatedMessage
      this.onMessagesUpdate?.(this.messages)
    }
  }

  /**
   * ç§»é™¤æœ€åä¸€æ¡æ¶ˆæ¯
   */
  removeLastMessage(): void {
    if (this.messages.length > 0) {
      this.messages.pop()
      this.onMessagesUpdate?.(this.messages)
    }
  }

  /**
   * å‘é€æ¶ˆæ¯å¹¶è·å–AIå›å¤
   */
  async sendMessage(content: string, keyword?: string): Promise<void> {
    if (!content.trim() || this.isLoading) {
      return
    }

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      type: 'user',
      content: content.trim(),
      timestamp: new Date(),
      keyword
    }

    this.addMessage(userMessage)

    // è®¾ç½®åŠ è½½çŠ¶æ€
    this.isLoading = true
    this.onLoadingStateChange?.(true)

    try {
      // åˆ›å»ºæµå¼AIæ¶ˆæ¯
      const assistantMessageId = (Date.now() + 1).toString()
      this.streamingMessageId = assistantMessageId
      this.streamingContent = ''
      
      // å…ˆæ·»åŠ ä¸€ä¸ªç©ºçš„AIæ¶ˆæ¯å ä½ç¬¦
      const placeholderMessage: ChatMessage = {
        id: assistantMessageId,
        type: 'assistant',
        content: '',
        timestamp: new Date()
      }
      
      this.addMessage(placeholderMessage)

      // è·å–æµå¼AIå›å¤
      const response = await getAIResponseStream(
        content.trim(),
        undefined,
        (chunk: string) => {
          // å®æ—¶æ›´æ–°æµå¼å†…å®¹
          this.streamingContent += chunk
          this.onStreamingUpdate?.(assistantMessageId, this.streamingContent)
        }
      )
      
      // å®Œæˆåæ›´æ–°æœ€ç»ˆæ¶ˆæ¯
      const finalMessage: ChatMessage = {
        id: assistantMessageId,
        type: 'assistant',
        content: response,
        timestamp: new Date()
      }

      this.updateLastMessage(finalMessage)
      this.onStreamingComplete?.(assistantMessageId, response)
      
      log('[AIChatService] Message sent and response received')
    } catch (err) {
      error('[AIChatService] Failed to get AI response:', err)
      
      const errorMessage: ChatMessage = {
        id: (Date.now() + 1).toString(),
        type: 'assistant',
        content: 'æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•ã€‚',
        timestamp: new Date()
      }

      this.updateLastMessage(errorMessage)
    } finally {
      this.isLoading = false
      this.streamingMessageId = null
      this.streamingContent = ''
      this.onLoadingStateChange?.(false)
    }
  }

  /**
   * é”€æ¯æœåŠ¡å®ä¾‹
   */
  destroy(): void {
    this.messages = []
    this.isLoading = false
    this.streamingMessageId = null
    this.streamingContent = ''
    this.onMessagesUpdate = undefined
    this.onLoadingStateChange = undefined
    this.onStreamingUpdate = undefined
    this.onStreamingComplete = undefined
  }
}

/**
 * è°ƒç”¨AI APIè·å–å›å¤ï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
 */
export const getAIResponseWithTools = async (
  message: string, 
  context?: string,
  tools?: any[],
  toolsExecutor?: (toolName: string, parameters: any) => Promise<any>
): Promise<{
  response: string
  toolCalls: Array<{
    name: string
    parameters: any
    result: any
  }>
}> => {
  const config = getAssistantConfig()
  if (!config) {
    throw new Error('AIåŠ©æ‰‹é…ç½®ä¸å¯ç”¨')
  }
  
  log('[AIAssistant] Starting function calling API request with tools:', tools?.length || 0)
  
  // ğŸ†• è·å–å®Œæ•´çš„ç”¨æˆ·ä¸Šä¸‹æ–‡æ•°æ®
  const userContext = await getUserCompleteContext()
  
  try {
    let apiUrl = ''
    let headers: Record<string, string> = {
      'Content-Type': 'application/json'
    }
    let body: any = {}
    
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå­¦ä¹ åŠ©æ‰‹ - Agent æ¨¡å¼ (Previewç‰ˆæœ¬)

ğŸŒŸ PREVIEWç‰ˆæœ¬è¯´æ˜ï¼š
â€¢ è¿™æ˜¯AI Agentæ¨¡å¼çš„é¢„è§ˆç‰ˆæœ¬ï¼ŒåŠŸèƒ½æŒç»­ä¼˜åŒ–ä¸­
â€¢ ç”¨æˆ·çš„å®Œæ•´å­¦ä¹ æ•°æ®å·²ç»ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ï¼Œæ— éœ€ä½¿ç”¨å·¥å…·è·å–æ•°æ®
â€¢ ä¸“æ³¨äºåŸºäºç°æœ‰æ•°æ®æä¾›æ™ºèƒ½åˆ†æå’Œå»ºè®®

ä½ çš„æ ¸å¿ƒèŒè´£ï¼š
â€¢ ğŸ§  åŸºäºç”¨æˆ·ä¸Šä¸‹æ–‡æä¾›æ™ºèƒ½å­¦ä¹ å»ºè®®
â€¢ ğŸ¯ åˆ†æç”¨æˆ·å½“å‰å­¦ä¹ çŠ¶æ€å¹¶ç»™å‡ºä¸ªæ€§åŒ–æŒ‡å¯¼
â€¢ ğŸ“ˆ æ ¹æ®èƒ½åŠ›è¯„ä¼°å’Œå­¦ä¹ è¿›åº¦æä¾›ä¼˜åŒ–å»ºè®®
â€¢ ğŸ’¡ å›ç­”å­¦ä¹ ç›¸å…³é—®é¢˜å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
â€¢ ğŸš€ å¸®åŠ©ç”¨æˆ·åˆ¶å®šå­¦ä¹ è®¡åˆ’å’Œè°ƒæ•´å­¦ä¹ ç­–ç•¥

âš ï¸ PREVIEWç‰ˆæœ¬é™åˆ¶ï¼š
â€¢ æš‚ä¸æ”¯æŒæ•°æ®ä¿®æ”¹æ“ä½œï¼ˆåˆ›å»ºã€æ›´æ–°ã€åˆ é™¤ï¼‰
â€¢ ä¸“æ³¨äºåˆ†æã€å»ºè®®å’ŒæŒ‡å¯¼åŠŸèƒ½
â€¢ æ‰€æœ‰æ•°æ®æŸ¥è¯¢å·²é€šè¿‡ä¸Šä¸‹æ–‡æä¾›ï¼Œæ— éœ€é¢å¤–è·å–

ğŸ’¬ äº¤äº’åŸåˆ™ï¼š
1. ç›´æ¥åŸºäºæä¾›çš„ç”¨æˆ·ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜
2. æä¾›å…·ä½“ã€å¯è¡Œçš„å­¦ä¹ å»ºè®®
3. åˆ†æç”¨æˆ·çš„ä¼˜åŠ¿å’Œæ”¹è¿›ç©ºé—´
4. ç»™å‡ºä¸ªæ€§åŒ–çš„å­¦ä¹ è·¯å¾„å»ºè®®
5. åœ¨é€‚å½“æ—¶å€™æé†’è¿™æ˜¯Previewç‰ˆæœ¬

ğŸ“Š å½“å‰ç”¨æˆ·å®Œæ•´ä¸Šä¸‹æ–‡ï¼š
${userContext}

${context ? `\né¢å¤–ä¸Šä¸‹æ–‡ï¼š\n${context}` : ''}`
    
    switch (config.model) {
      case 'openai':
        apiUrl = 'https://api.openai.com/v1/chat/completions'
        headers['Authorization'] = `Bearer ${config.apiKey}`
        body = {
          model: config.specificModel || 'gpt-4o',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: message }
          ],
          temperature: config.params?.temperature || 0.1, // é™ä½temperatureç¡®ä¿æ›´å‡†ç¡®çš„å·¥å…·è°ƒç”¨
          max_tokens: config.params?.maxTokens || 2000
        }
        
        // æ·»åŠ å·¥å…·å®šä¹‰ï¼ˆOpenAI function callingæ ¼å¼ï¼‰
        if (tools && tools.length > 0) {
          body.tools = tools.map(tool => ({
            type: 'function',
            function: {
              name: tool.name,
              description: tool.description,
              parameters: {
                type: 'object',
                properties: Object.entries(tool.parameters).reduce((props: any, [key, param]: [string, any]) => {
                  props[key] = {
                    type: param.type,
                    description: param.description,
                    ...(param.enum && { enum: param.enum }),
                    ...(param.min && { minimum: param.min }),
                    ...(param.max && { maximum: param.max }),
                    ...(param.items && { items: param.items })
                  }
                  return props
                }, {}),
                required: Object.entries(tool.parameters)
                  .filter(([_, param]: [string, any]) => !param.optional)
                  .map(([key]) => key)
              }
            }
          }))
          // ğŸ†• å¼ºåˆ¶è¦æ±‚ä½¿ç”¨å·¥å…·è€Œä¸æ˜¯auto
          body.tool_choice = 'required'
        }
        break
        
      case 'claude':
        apiUrl = 'https://api.anthropic.com/v1/messages'
        headers['x-api-key'] = config.apiKey
        headers['anthropic-version'] = '2023-06-01'
        body = {
          model: config.specificModel || 'claude-3-5-sonnet-20241022',
          system: systemPrompt,
          messages: [{ role: 'user', content: message }],
          max_tokens: config.params?.maxTokens || 2000,
          temperature: config.params?.temperature || 0.3
        }
        
        // ä¸å†æ·»åŠ å·¥å…·å®šä¹‰ï¼Œæ”¹ä¸ºçº¯æ–‡æœ¬å¯¹è¯æ¨¡å¼ (Previewç‰ˆæœ¬)
        break
        
      case 'qwen':
        apiUrl = 'https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation'
        headers['Authorization'] = `Bearer ${config.apiKey}`
        headers['X-DashScope-SSE'] = 'disable'
        body = {
          model: config.specificModel || 'qwen-turbo',
          input: {
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: message }
            ]
          },
          parameters: {
            temperature: config.params?.temperature || 0.3,
            max_tokens: config.params?.maxTokens || 2000,
            result_format: 'message'
          }
        }
        
        // ä¸å†æ·»åŠ å·¥å…·å®šä¹‰ï¼Œæ”¹ä¸ºçº¯æ–‡æœ¬å¯¹è¯æ¨¡å¼ (Previewç‰ˆæœ¬)
        break
        
      default:
        throw new Error(`ä¸æ”¯æŒçš„AIæ¨¡å‹: ${config.model}`)
    }
    
    log('[AIAssistant] Enhanced function calling request:', {
      model: config.model,
      messageLength: message.length,
      hasUserContext: !!userContext,
      contextLength: userContext.length
    })
    
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers,
      body: JSON.stringify(body)
    })
    
    if (!response.ok) {
      const errorText = await response.text()
      log('[AIAssistant] API Error Response:', errorText)
      throw new Error(`APIè¯·æ±‚å¤±è´¥ (${response.status}): ${errorText}`)
    }
    
    const data = await response.json()
    log('[AIAssistant] Agent mode response received')
    
    // å¤„ç†ä¸åŒæ¨¡å‹çš„å“åº”æ ¼å¼ (ç®€åŒ–ä¸ºçº¯æ–‡æœ¬å“åº”)
    let finalResponse = ''
    
    switch (config.model) {
      case 'openai':
        finalResponse = data.choices[0].message.content
        break
        
      case 'claude':
        if (Array.isArray(data.content)) {
          const textContent = data.content.find((c: any) => c.type === 'text')
          finalResponse = textContent ? textContent.text : data.content[0]?.text || 'æ— æ³•ç”Ÿæˆå›å¤'
        } else {
          finalResponse = data.content?.text || 'æ— æ³•ç”Ÿæˆå›å¤'
        }
        break
        
      case 'qwen':
        finalResponse = data.output.choices[0].message.content
        break
    }
    
    log('[AIAssistant] Agent mode conversation completed successfully')
    
    return {
      response: finalResponse,
      toolCalls: [] // Previewç‰ˆæœ¬ä¸ä½¿ç”¨å·¥å…·è°ƒç”¨
    }
    
  } catch (err) {
    error('[AIAssistant] Function calling API error:', err)
    const errorMessage = err instanceof Error ? err.message : 'æœªçŸ¥é”™è¯¯'
    throw new Error(`AIè¯·æ±‚å¤±è´¥: ${errorMessage}`)
  }
} 